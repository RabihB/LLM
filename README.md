# LLM
Testing with Local/cloud LLMs

Setting up the environment and running the meta Llama2 model 13b over Colab. Make sure that you are running a GPU instance on Colab.
